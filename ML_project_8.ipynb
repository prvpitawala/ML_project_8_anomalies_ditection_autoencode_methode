{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# In this notebook, we are going to create a model for detecting anomalies using the autoencoder method."
      ],
      "metadata": {
        "id": "flKLr8i5TZSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "make the dataset and train the model on it"
      ],
      "metadata": {
        "id": "XHdmPvhbTyL4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tOtgDLf1lImR"
      },
      "outputs": [],
      "source": [
        "# import the lib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random normal data\n",
        "normal_data = np.random.normal(0, 1, size=(1000, 32))\n",
        "normal_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRM9eXkMtulk",
        "outputId": "c10ad572-4b84-453a-a484-e1ab8d30c0d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the train data and the train labels\n",
        "train_data = normal_data\n",
        "train_labels = np.array(len(normal_data)*[0])  # make 0 array as length same as the nrmal data length"
      ],
      "metadata": {
        "id": "u8KQPxDGGjim"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlBt-vMVGzT1",
        "outputId": "6bd18cb7-f0fc-47d9-bf49-b0c3dacf0011"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data set to the train and the test set\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "aizomEDFtD3N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the x_train shape\n",
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqKYjUZYIoKh",
        "outputId": "1b691c19-4609-41fd-d4f4-bee005f08872"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the imput shape\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "# set the encoder\n",
        "encoder = models.Sequential([\n",
        "    layers.Input(shape=(input_dim,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(16, activation='relu')\n",
        "])\n",
        "\n",
        "# set the decoder\n",
        "decoder = models.Sequential([\n",
        "    layers.Input(shape=(16,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(input_dim, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# set the autoencoder usisng the encoder and the decoder\n",
        "autoencoder = models.Sequential([\n",
        "    encoder,\n",
        "    decoder\n",
        "])\n",
        "\n",
        "# compile the auto encoder model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "Wn5fewbYtGKe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the early stop callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", patience = 10, restore_best_weights = True)\n",
        "\n",
        "\n",
        "# fit the auto encoder model\n",
        "autoencoder.fit(x_train,\n",
        "                x_train,\n",
        "                epochs= 200,\n",
        "                batch_size=128,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks = early_stop)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS_qRb6KtIvU",
        "outputId": "d69c2294-aafe-4470-e8c3-5abbf49b6c02"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "7/7 [==============================] - 2s 45ms/step - loss: 1.2482 - val_loss: 1.2484\n",
            "Epoch 2/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.2322 - val_loss: 1.2273\n",
            "Epoch 3/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.2038 - val_loss: 1.1884\n",
            "Epoch 4/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.1554 - val_loss: 1.1292\n",
            "Epoch 5/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.0931 - val_loss: 1.0704\n",
            "Epoch 6/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.0459 - val_loss: 1.0394\n",
            "Epoch 7/200\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.0250 - val_loss: 1.0258\n",
            "Epoch 8/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 1.0125 - val_loss: 1.0103\n",
            "Epoch 9/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 1.0007 - val_loss: 1.0045\n",
            "Epoch 10/200\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.9976 - val_loss: 1.0027\n",
            "Epoch 11/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.9955 - val_loss: 1.0005\n",
            "Epoch 12/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.9932 - val_loss: 0.9978\n",
            "Epoch 13/200\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.9905 - val_loss: 0.9949\n",
            "Epoch 14/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.9874 - val_loss: 0.9918\n",
            "Epoch 15/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.9839 - val_loss: 0.9884\n",
            "Epoch 16/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.9797 - val_loss: 0.9844\n",
            "Epoch 17/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.9746 - val_loss: 0.9800\n",
            "Epoch 18/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.9688 - val_loss: 0.9755\n",
            "Epoch 19/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.9629 - val_loss: 0.9702\n",
            "Epoch 20/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.9573 - val_loss: 0.9649\n",
            "Epoch 21/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.9513 - val_loss: 0.9594\n",
            "Epoch 22/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.9456 - val_loss: 0.9548\n",
            "Epoch 23/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.9395 - val_loss: 0.9519\n",
            "Epoch 24/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.9338 - val_loss: 0.9482\n",
            "Epoch 25/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.9281 - val_loss: 0.9443\n",
            "Epoch 26/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.9233 - val_loss: 0.9423\n",
            "Epoch 27/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.9187 - val_loss: 0.9402\n",
            "Epoch 28/200\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.9144 - val_loss: 0.9379\n",
            "Epoch 29/200\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.9105 - val_loss: 0.9357\n",
            "Epoch 30/200\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.9070 - val_loss: 0.9338\n",
            "Epoch 31/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.9038 - val_loss: 0.9312\n",
            "Epoch 32/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.9010 - val_loss: 0.9299\n",
            "Epoch 33/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8979 - val_loss: 0.9284\n",
            "Epoch 34/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8956 - val_loss: 0.9273\n",
            "Epoch 35/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8927 - val_loss: 0.9260\n",
            "Epoch 36/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8902 - val_loss: 0.9249\n",
            "Epoch 37/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8881 - val_loss: 0.9240\n",
            "Epoch 38/200\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.8858 - val_loss: 0.9240\n",
            "Epoch 39/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8835 - val_loss: 0.9227\n",
            "Epoch 40/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8815 - val_loss: 0.9227\n",
            "Epoch 41/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8797 - val_loss: 0.9215\n",
            "Epoch 42/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8771 - val_loss: 0.9215\n",
            "Epoch 43/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8754 - val_loss: 0.9196\n",
            "Epoch 44/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8732 - val_loss: 0.9203\n",
            "Epoch 45/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8714 - val_loss: 0.9186\n",
            "Epoch 46/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8692 - val_loss: 0.9175\n",
            "Epoch 47/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8670 - val_loss: 0.9168\n",
            "Epoch 48/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8648 - val_loss: 0.9157\n",
            "Epoch 49/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8625 - val_loss: 0.9153\n",
            "Epoch 50/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8608 - val_loss: 0.9125\n",
            "Epoch 51/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8591 - val_loss: 0.9131\n",
            "Epoch 52/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8568 - val_loss: 0.9117\n",
            "Epoch 53/200\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.8544 - val_loss: 0.9115\n",
            "Epoch 54/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8525 - val_loss: 0.9100\n",
            "Epoch 55/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8504 - val_loss: 0.9088\n",
            "Epoch 56/200\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.8486 - val_loss: 0.9072\n",
            "Epoch 57/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8466 - val_loss: 0.9070\n",
            "Epoch 58/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8448 - val_loss: 0.9060\n",
            "Epoch 59/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8434 - val_loss: 0.9030\n",
            "Epoch 60/200\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.8413 - val_loss: 0.9042\n",
            "Epoch 61/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8397 - val_loss: 0.9045\n",
            "Epoch 62/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8383 - val_loss: 0.9028\n",
            "Epoch 63/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8362 - val_loss: 0.9006\n",
            "Epoch 64/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8348 - val_loss: 0.9011\n",
            "Epoch 65/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8333 - val_loss: 0.9006\n",
            "Epoch 66/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8314 - val_loss: 0.8995\n",
            "Epoch 67/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8305 - val_loss: 0.8982\n",
            "Epoch 68/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8301 - val_loss: 0.8980\n",
            "Epoch 69/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8282 - val_loss: 0.8986\n",
            "Epoch 70/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8270 - val_loss: 0.8963\n",
            "Epoch 71/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8257 - val_loss: 0.8966\n",
            "Epoch 72/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8245 - val_loss: 0.8948\n",
            "Epoch 73/200\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.8234 - val_loss: 0.8963\n",
            "Epoch 74/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.8218 - val_loss: 0.8946\n",
            "Epoch 75/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.8202 - val_loss: 0.8938\n",
            "Epoch 76/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8193 - val_loss: 0.8938\n",
            "Epoch 77/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8180 - val_loss: 0.8927\n",
            "Epoch 78/200\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.8171 - val_loss: 0.8940\n",
            "Epoch 79/200\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.8156 - val_loss: 0.8915\n",
            "Epoch 80/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8144 - val_loss: 0.8914\n",
            "Epoch 81/200\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.8135 - val_loss: 0.8923\n",
            "Epoch 82/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8123 - val_loss: 0.8906\n",
            "Epoch 83/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8116 - val_loss: 0.8905\n",
            "Epoch 84/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8102 - val_loss: 0.8902\n",
            "Epoch 85/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8088 - val_loss: 0.8896\n",
            "Epoch 86/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8077 - val_loss: 0.8894\n",
            "Epoch 87/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8071 - val_loss: 0.8881\n",
            "Epoch 88/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8063 - val_loss: 0.8900\n",
            "Epoch 89/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8057 - val_loss: 0.8876\n",
            "Epoch 90/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8043 - val_loss: 0.8893\n",
            "Epoch 91/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8039 - val_loss: 0.8878\n",
            "Epoch 92/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8023 - val_loss: 0.8867\n",
            "Epoch 93/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8018 - val_loss: 0.8873\n",
            "Epoch 94/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.8007 - val_loss: 0.8856\n",
            "Epoch 95/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8000 - val_loss: 0.8856\n",
            "Epoch 96/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.7996 - val_loss: 0.8876\n",
            "Epoch 97/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7987 - val_loss: 0.8862\n",
            "Epoch 98/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.7985 - val_loss: 0.8847\n",
            "Epoch 99/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.7970 - val_loss: 0.8860\n",
            "Epoch 100/200\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.7961 - val_loss: 0.8847\n",
            "Epoch 101/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.7950 - val_loss: 0.8864\n",
            "Epoch 102/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.7945 - val_loss: 0.8854\n",
            "Epoch 103/200\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.7942 - val_loss: 0.8836\n",
            "Epoch 104/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.7930 - val_loss: 0.8863\n",
            "Epoch 105/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.7922 - val_loss: 0.8858\n",
            "Epoch 106/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.7914 - val_loss: 0.8844\n",
            "Epoch 107/200\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.7905 - val_loss: 0.8839\n",
            "Epoch 108/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.7900 - val_loss: 0.8860\n",
            "Epoch 109/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7894 - val_loss: 0.8850\n",
            "Epoch 110/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7888 - val_loss: 0.8838\n",
            "Epoch 111/200\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7883 - val_loss: 0.8842\n",
            "Epoch 112/200\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.7874 - val_loss: 0.8851\n",
            "Epoch 113/200\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.7869 - val_loss: 0.8846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd4694f6230>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the autoencoder mdoel\n",
        "autoencoder.evaluate(x_test[y_test == 0], x_test[y_test == 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FudumwOLF094",
        "outputId": "7708b77e-374e-43bd-e0dc-267ce49358fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 0.8836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8836498260498047"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make another dataset and detect the anomalys"
      ],
      "metadata": {
        "id": "FgyFAORDT_-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now lets make a anomaly and the normaly (wat we are trainded for) data set for seprate the anomaly data\n",
        "\n",
        "normal_data_2  = np.random.normal(0, 1, size = (1000, 32))\n",
        "anomaly_data_2 = np.random.normal(7, 2, size = (300, 32))"
      ],
      "metadata": {
        "id": "uHOcZEpuJl4O"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mix the anomal and the normal data\n",
        "\n",
        "data = np.vstack([normal_data_2, anomaly_data_2])\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O23MnAE8Kwp0",
        "outputId": "eb29c194-2ba1-49e2-f903-35e01ced778c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1300, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the labels\n",
        "# lets difine as normal data as 0 and anomaly data 1\n",
        "labels = np.array([0]*len(normal_data_2) + [1]*len(anomaly_data_2))"
      ],
      "metadata": {
        "id": "4fKjmNUGLQdR"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate reconstruction errors for all data\n",
        "reconstructed_data = autoencoder.predict(data)\n",
        "mse = np.mean(np.power(data - reconstructed_data, 2), axis=1)\n",
        "\n",
        "print(len(mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fmPSMjc9LXh",
        "outputId": "45192349-3a09-4364-bf97-c5413f257716"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "1300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a threshold for anomaly detection (you can adjust this threshold)\n",
        "threshold = 1.7  # this is we can adjust how we want\n",
        "\n",
        "# Classify anomalies based on the threshold\n",
        "predictions = (mse > threshold).astype(int)\n",
        "predictions_2 = [x for x in predictions if x == 1]\n",
        "\n",
        "print(len(predictions))\n",
        "print(len(predictions_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54akupZytKcd",
        "outputId": "f4c5bbc0-0c26-4ac0-a416-7882dab03534"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1300\n",
            "301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions[800:])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieMGXAdW5uMD",
        "outputId": "9b64579f-a217-4781-85b7-952eb6fe7dc6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the model has successfully identified the anomalies correctly. Therefore, our model can predict the anomalies in that dataset accurately using the 1.7 threshold."
      ],
      "metadata": {
        "id": "BbGAeYl5CZLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "end"
      ],
      "metadata": {
        "id": "xf4n6rHpUsZN"
      }
    }
  ]
}